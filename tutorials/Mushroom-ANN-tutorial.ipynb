{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Your Own Neural Network\n",
    "In this section we will build a simple neural network, train it and validate it on a sample test data.\n",
    "For this exercise, we will use the [Mushroom dataset from the Audobon Society Field Guide](https://archive.ics.uci.edu/dataset/73/mushroom>).\n",
    "This dataset includes 22 physical characteristics of ~8,000 mushrooms spanning 23 species of gilled mushrooms in the Agaricus and Lepiota Family.\n",
    "Our task is to predict whether a mushroom is edible or poisonous based on its physical characteristics.\n",
    "\n",
    "By the end of this excercise participants will be able to:\n",
    "\n",
    "1. Import the Mushroom dataset from the UCI Machine Learning Repository.\n",
    "2. Examine and preprocess the data to be fed to the neural network.\n",
    "3. Build a sequential model neural network using TensorFlow Keras.\n",
    "4. Evaluate the model's performance on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing required libraries and data\n",
    "The Mushroom dataset is available in the University of California, Irvine Machine Learning Repository, which is a popular repository for machine learning datasets.\n",
    "Conveniently, the ``ucimlrepo`` Python package provides a simple interface to download and load datasets directly from this repository.\n",
    "\n",
    "First, we will import the Mushroom dataset using the ``ucimlrepo`` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the Mushroom dataset has 8124 instances (samples) and 22 features (physical characteristics), and there are missing values in the dataset.\n",
    "Now that we have loaded the dataset, let's separate the features (``X``) from the target variable and examine the structure of our feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's isolate and examine our target variable ``y``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, a Dtype (data type) specifies how the data in a column should be stored and interpreted.\n",
    "When we see a Dtype of ``object``, it typically means the column contains strings or a mix of different data types. Let's examine our data further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the features are categorical variables stored as strings (which pandas represents as ``object`` Dtype). \n",
    "Each feature is encoded with single-character values that represent specific categories.\n",
    "\n",
    "For a complete reference of all categorical values and their meanings, visit the [UCI Mushroom Dataset page](https://archive.ics.uci.edu/dataset/73/mushroom).\n",
    "\n",
    "Here are a few examples of the categorical encodings:\n",
    " \n",
    " * **cap-shape**: 'x' (convex), 'b' (bell), 'f' (flat), etc.\n",
    " * **cap-color**: 'n' (brown), 'y' (yellow), 'w' (white), etc.\n",
    " * **odor**: 'p' (pungent), 'a' (almond), 'l' (anise), etc.\n",
    "\n",
    "\n",
    "Next, let's take a look at the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable contains two categorical labels: ``p`` (poisonous) and ``e`` (edible).\n",
    "With this insight into our dataset's structure, our next step is to prepare the data for model training.\n",
    "\n",
    "\n",
    "**Thought Challenge:** What are some things that you have noticed about the data that you think we will need to fix before feeding it to the neural network? Pause here and write down your thoughts before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data pre-processing\n",
    "Our exploration of the Mushroom dataset reveals a collection of 8124 samples with 22 features and a single target variable. Before proceeding with model development, several preprocessing challenges need to be addressed:\n",
    "\n",
    " 1. The dataset contains missing values that require handling.\n",
    " 2. All features are categorical, encoded as text strings (represented as ``object`` type in pandas).\n",
    " 3. The target variable itself is categorical, using ``p`` to indicate poisonous mushrooms and ``e`` for edible ones.\n",
    "\n",
    "First, let's handle the missing values. Let's see how many missing values are in the dataset, and where they are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that ``stalk-root`` is missing data for 2480 samples, while all other features have complete data.\n",
    "Let's remove this column from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to encode our categorical variables into a format suitable for the neural network. We'll use one-hot encoding via ``pd.get_dummies()`` to transform each categorical feature into multiple binary columns. For example, if a feature has three possible values (A, B, C), it will be converted into three separate columns, where only one column will have a value of 1 (True) and the others 0 (False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of having 22 features, we have 112 features, each representing a binary True/False value for each categorical value in the original features.\n",
    "\n",
    "Finally, let's encode the target variable. We will simply convert the string labels ``p`` and ``e`` into binary numeric values of 1 and 0, respectively.\n",
    "In this case, 1 will represent a poisonous mushroom and 0 will represent an edible mushroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now would be a good time to check the class distribution of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a roughly balanced dataset with 51.8% of the samples being edible and 48.2% being poisonous.\n",
    "We can now split the dataset into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Train-Test Split**\n",
    "\n",
    "The code above divides our data into training and testing sets, creating four objects:\n",
    "``X_train``, ``X_test``, ``y_train``, and ``y_test``.\n",
    "\n",
    "| Parameter | Purpose | In Our Example |\n",
    "|-----------|---------|----------------|\n",
    "| `test_size` | Determines what portion of data is reserved for testing | 30% for testing, 70% for training |\n",
    "| `stratify` | Maintains the same class distribution in both splits | Ensures balanced representation of poisonous/edible classes |\n",
    "| `random_state` | Controls the randomization for reproducible results | Set to 123 for consistent splits across runs |\n",
    "\n",
    "**Why These Parameters Matter:**\n",
    "\n",
    "* **Test Size**: Finding the right balance between having enough data for training while reserving sufficient data for testing is crucial. Too little test data may not reliably assess model performance; too little training data may limit learning.\n",
    "\n",
    "* **Stratification**: When working with classification problems, maintaining class proportions is essential. Without stratification, you might accidentally create a test set with disproportionate class representation, leading to misleading evaluation metrics.\n",
    "\n",
    "* **Reproducibility**: Setting a random seed ensures you can reproduce your experiments exactly, which is fundamental for scientific rigor and debugging.\n",
    "\n",
    "**Tip**: While our dataset has roughly balanced classes, stratification becomes especially important with imbalanced datasets. Always consider using ``stratify`` as a best practice.\n",
    "\n",
    "## Step 3: Building a sequential model neural network\n",
    "Now we'll create a simple neural network for our mushroom classification task. The model will consist of:\n",
    "\n",
    "- An **input layer** that matches our feature dimensions\n",
    "- A **hidden layer** with 10 neurons and ReLU activation\n",
    "- An **output layer** with sigmoid activation for binary classification\n",
    "\n",
    "This architecture provides a good starting point for understanding how neural networks learn from tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought Challenge**: How many parameters does the model have? Can you calculate this manually and get the same result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Neural Network**\n",
    "\n",
    "With our model built and compiled, we can now train it on our data. Before executing the training code, let’s understand the key parameters we’ll use:\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| **validation_split=0.2** | Reserves 20% of training data to evaluate performance during training, without affecting model weights |\n",
    "| **epochs=5** | Number of complete passes through the dataset; more epochs allow for more learning iterations but risk overfitting |\n",
    "| **batch_size=32** | Number of samples processed before weight update; affects memory usage, training speed, and convergence behavior |\n",
    "| **verbose=2** | Controls output level (0=silent, 1=progress bar, 2=one line per epoch) |\n",
    "\n",
    "**Thought Challenge**: How does the choice of ``batch_size`` affect the training process?\n",
    "\n",
    "Now let's train our model with these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand what this output tells us:\n",
    "\n",
    "1. **Progress metrics**:\n",
    "  - ``143/143``: Shows progress through the training batches; 143 batches were completed out of 143, and each batch contains 32 samples (as specified by ``batch_size=32``)\n",
    "  - ``0s``: Indicates the time taken for each epoch; here, the first epoch took <1 second to complete.\n",
    "  - ``2ms/step``: This indicates the average time taken per training step (one forward and backward pass through a single batch) during training.\n",
    "\n",
    "2. **Training metrics**:\n",
    "  - ``accuracy: 0.8828``: Represents the accuracy of the model on the training dataset. The accuracy value of approximately 0.8828 indicates that the model correctly predicted 88.28% of the training samples.\n",
    "  - ``loss: 0.4267``: Represents the training loss value (using binary cross-entropy loss function) on the training dataset. Higher loss values indicate that the model's predictions are further from the true labels.\n",
    "\n",
    "3. **Validation metrics**:\n",
    "  - ``val_accuracy: 0.9552``: Represents the accuracy of the model on the validation dataset. The accuracy value of approximately 0.9552 indicates that the model correctly predicted 95.52% of the validation samples.\n",
    "  - ``val_loss: 0.2148``: Represents the validation loss value (using binary cross-entropy loss function) on the validation dataset. Lower loss values indicate that the model's predictions are closer to the true labels.\n",
    "\n",
    "Looking at our training results after 5 epochs, we can observe:\n",
    "\n",
    "1. The model achieved excellent performance, with final training accuracy of 99.78% and validation accuracy of 99.82%.\n",
    "2. Both training and validation loss steadily decreased across epochs, indicating consistent learning.\n",
    "3. Validation metrics consistently tracked close to training metrics, suggesting the model generalizes well rather than memorizing the training data.\n",
    "\n",
    "Let's visualize our training progress before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This high performance is promising, but we should verify it on our completely separate test set, which the model has never seen during training. This will give us the most reliable measure of how well our model might perform in real-world scenarios.\n",
    "## Step 4: Evaluate the model's performance on test data\n",
    "The true test of our model's capabilities comes from evaluating it on our completely separate test dataset. Let's see how our neural network performs when classifying mushrooms it has never encountered before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary classification problem like our (poisonous vs edible), the model outputs probabilities between 0 and 1 for each sample. Let's show the first sample's prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the probability for the first mushroom sample in the test set.\n",
    "The output is a single value between 0 and 1, where:\n",
    " - Values closer to 1 indicate the model is more confident that the sample is poisonous.\n",
    " - Values closer to 0 indicate the model is more confident that the sample is edible.\n",
    "\n",
    "For example, our output value is 0.00026, which means that the model is 99.99% confident that the sample is edible.\n",
    "\n",
    "The model outputs probability values, but for practical mushroom classification, we need definitive \"edible\" or \"poisonous\" predictions. We need to convert these continuous probability values into discrete class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs what's called \"thresholding\":\n",
    "\n",
    "1. First, we compare each probability to the threshold value (0.5)\n",
    "   \n",
    "   - If probability > 0.5, the result is True (model thinks it's more likely poisonous)\n",
    "   - If probability ≤ 0.5, the result is False (model thinks it's more likely edible)\n",
    "\n",
    "2. Then, we convert these True/False values to integers (1/0) with ``.astype(int)``\n",
    "   \n",
    "   - True becomes 1 (poisonous)\n",
    "   - False becomes 0 (edible)\n",
    "\n",
    "The 0.5 threshold represents the decision boundary - the point where the model is equally confident in either class. We could adjust this threshold if we wanted to be more conservative about certain types of errors (e.g., lowering the threshold would classify more mushrooms as poisonous, reducing the chance of missing toxic ones).\n",
    "\n",
    "\n",
    "Now, let's visualize the model's prediction accuracy with a **confusion matrix**. \n",
    "This will allow us to see how many correct vs incorrect predictions were made using the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix visualization shows how well our model classifies mushrooms as edible or poisonous. The matrix is a 2x2 grid where:\n",
    "\n",
    "* The y-axis (Truth) shows the actual class of the mushrooms\n",
    "* The x-axis (Predicted) shows what our model predicted\n",
    "* Each cell contains the count of predictions falling into that category\n",
    "* The heatmap coloring provides visual intensity, where lighter colors indicate higher counts\n",
    "\n",
    "Reading the matrix:\n",
    "\n",
    "* **Top-left**: True Negatives (TN) - Correctly identified edible mushrooms\n",
    "* **Top-right**: False Positives (FP) - Edible mushrooms incorrectly classified as poisonous\n",
    "* **Bottom-left**: False Negatives (FN) - Poisonous mushrooms incorrectly classified as edible\n",
    "* **Bottom-right**: True Positives (TP) - Correctly identified poisonous mushrooms \n",
    "\n",
    "**Key Classification Metrics**\n",
    "\n",
    "From these confusion matrix values, we can calculate several important evaluation metrics:\n",
    "\n",
    "| Metric | Definition | Interpretation for Mushrooms |\n",
    "|--------|------------|----------------------------|\n",
    "| **Accuracy** | (TP + TN)/(TP + TN + FP + FN) | Percentage of all mushrooms correctly classified |\n",
    "| **Precision** | TP/(TP + FP) | When model predicts \"poisonous,\" how often is it right? |\n",
    "| **Recall** | TP/(TP + FN) | Of all poisonous mushrooms, how many did we correctly identify? |\n",
    "| **F1-Score** | 2 × (Precision × Recall)/(Precision + Recall) | Harmonic mean of precision and recall; useful when you need to balance both |\n",
    "| **Specificity** | TN/(TN + FP) | Of all edible mushrooms, how many did we correctly identify? |\n",
    "\n",
    "**Thought Challenge**: Which prediction metric is most important for this model? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also print the full classification report of this model using code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our model is 99.79%.\n",
    "99.79% of the time, this model predicted the correct label on the test data.\n",
    "\n",
    "**Thought Challenge**: Did we build a successful model? Why or why not? Is there anything we can do to improve the model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
